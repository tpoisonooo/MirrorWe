"""
å¢å¼ºç‰ˆ Person ç±»ï¼Œæ”¯æŒåŠ è½½æœ¬åœ°æ¶ˆæ¯æ•°æ®
"""

from abc import ABC, abstractmethod
import json
import os
import sys
import inspect
import aiofiles
from pathlib import Path
from typing import List, Dict, Any
from loguru import logger
from ..primitive import json_parser
from ..prompt import FRIEND_BIO
from ..primitive import parse_multiline_json_objects_async, try_load_text
from ..primitive import LLM
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
from mirror.core.memory import MemoryStream
from mirror.core.personality import Personality

class Person(ABC):
    """å¢å¼ºç‰ˆ Person ç±»ï¼Œæ”¯æŒåŠ è½½æœ¬åœ°æ¶ˆæ¯æ•°æ®"""
    
    def __init__(self, wxid: str):
        self.wxid = wxid
        self.memory = MemoryStream()
        self.personality = Personality()
        self.analysis_result = {}  # å­˜å‚¨åˆ†æç»“æœ
        self.bio = ""
        
        self.TAG_YOU = "å¯¹æ–¹"
        self.TAG_ME = "æˆ‘"
        current_file = inspect.getfile(self.__class__)
        data_dir = os.path.join(os.path.dirname(current_file), "..", "..", "data")
        self.wxid_dir = os.path.join(data_dir, 'friends', self.wxid)
        self.basic_path = os.path.join(self.wxid_dir, "basic.json")
        self.private_path = os.path.join(self.wxid_dir, "message.jsonl")
        self.group_path = os.path.join(self.wxid_dir, "group_segment.jsonl")
        self.llm = LLM() 

    async def initialize(self):
        # å°è¯•åŠ è½½æœ¬åœ°æ¶ˆæ¯æ•°æ®
        group_file_size = os.path.getsize(self.group_path) if os.path.exists(self.group_path) else 0

        # ç¾¤é‡Œä¸è¯´è¯ã€ä¹Ÿä¸æ˜¯å¾®ä¿¡ç›´æ¥å¥½å‹çš„ï¼ˆæ²¡æœ‰ basicï¼‰ï¼Œè·³è¿‡
        if group_file_size < 16*1024 and not os.path.exists(self.basic_path):
            return

        name = await self._load_local_messages([self.private_path, self.group_path])
        
        async def analysis():
            # ç»å…¸ç»Ÿè®¡
            if self.memory:
                await self._analyze_personality()
                await self._setup_personality_from_analysis()
                logger.info(f"Person {self.wxid}: åŠ è½½äº† {len(self.memory)} æ¡æ¶ˆæ¯ï¼Œå®Œæˆä¸ªæ€§åˆ†æ")
            else:
                logger.info(f"Person {self.wxid}: æ²¡æœ‰æ‰¾åˆ°æœ¬åœ°æ¶ˆæ¯æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤ä¸ªæ€§")
        
        await self.brief_bio(name=name)
        await analysis()


    async def brief_bio(self, name:str) -> str:
        """ç”Ÿæˆæœ‹å‹çš„  bio.md æ–‡ä»¶"""
        basic = await try_load_text(self.basic_path)
        bio_path = os.path.join(self.wxid_dir, "bio.md")
        bio = await try_load_text(bio_path)

        if not basic and not self.memory.private and len(self.memory.group) < 64:
            return "" # æ— æ³•ç”Ÿæˆç”»åƒ
        
        # æŒ‰ LLM æœ€å¤§é•¿åº¦ï¼Œæˆªæ–­ç™¾åˆ†ä¹‹å¤šå°‘ä¸Šä¸‹æ–‡
        max_text_size = self.llm.backend.max_token_size * 2 * 0.7
        cur_text_size = len(basic) + len(bio) + len(str(self.memory.private)) + len(str(self.memory.group))
        cut_ratio = max_text_size / cur_text_size
        if cut_ratio > 1.0:
            cut_private_index = 0
            cut_group_index = 0
        else:
            cut_private_index = max(0, int(cut_ratio * len(self.memory.private)))
            cut_group_index = max(0, int(cut_ratio * len(self.memory.group)))

        private = self.memory.private[-cut_private_index:]
        group = self.memory.group[-cut_group_index:]

        prompt = FRIEND_BIO.format(
            name=name,
            basic=basic,
            bio=bio,
            private=json.dumps(private, ensure_ascii=False, indent=2), 
            group=json.dumps(group, ensure_ascii=False, indent=2))
        # ä½¿ç”¨æ–°çš„LLMé€‚é…å™¨
        try:
            self.bio = await self.llm.chat_text(prompt)
        except Exception as e:
            self.bio = str(e)
        with open(bio_path, "w", encoding="utf-8") as f:
            f.write(self.bio)

    async def _load_local_messages(self, message_files: List[str]):
        """åŠ è½½ message.jsonl å’Œ group_segment.jsonl æ–‡ä»¶"""

        name = 'æŸä½å¥½å‹'
        try:
            total_loaded = 0
            # è§£æå¤šè¡ŒJSONæ ¼å¼
            for messages_file in message_files:
                if not os.path.exists(messages_file):
                    continue
                
                file_loaded = 0
                async for obj in parse_multiline_json_objects_async(messages_file):
                    data = obj.get('data', {})
                    is_self = data.get('self', False)
                    content = data.get('content', '').strip()
                    name = data.get('pushContent', ':').split(':')[0].strip()
                    ts = data.get('timestamp', 0)

                    if obj.get('messageType') == '60001':
                        # dt = datetime.fromtimestamp(ts)
                        # formatted = dt.strftime('%Y%m%d %H%M%S')
                        if is_self:
                            message = {"content":f"{self.TAG_ME}:{content}", "ts":ts}
                        else:
                            message = {"content":f"{name}:{content}", "ts":ts}
                        self.memory.add(private_chat=message)
                        file_loaded += 1
                    elif obj.get('messageType') == '80001':
                        message = {"content":f"{name}:{content}", "ts":ts}
                        self.memory.add(group_chat=message)
                        file_loaded += 1
                
                total_loaded += file_loaded
                logger.info(f"ä» {messages_file} åŠ è½½äº† {file_loaded} æ¡æœ‰æ•ˆæ¶ˆæ¯")
            
            logger.info(f"æ€»å…±åŠ è½½äº† {total_loaded} æ¡æœ‰æ•ˆæ¶ˆæ¯")
            
        except Exception as e:
            logger.error(f"åŠ è½½æœ¬åœ°æ¶ˆæ¯æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        return name
    
    async def _analyze_personality(self):
        """åŸºäºæ¶ˆæ¯æ•°æ®è¿›è¡Œä¸ªæ€§åˆ†æ"""
        # ä» memory ä¸­è·å–æ¶ˆæ¯æ•°æ®
        if not self.memory:
            self.analysis_result = self._get_default_analysis()
            return
        
        try:
            # æå–æ¶ˆæ¯å†…å®¹
            contents = []
            timestamps = []
            
            for msg in self.memory:
                if not isinstance(msg, dict):
                    continue
                    
                role = msg.get('role', '')
                if role == self.TAG_ME:
                    continue  # è·³è¿‡è‡ªå·±çš„æ¶ˆæ¯

                content = msg.get('content', '').strip()
                if content:
                    contents.append(content)
                    ts = msg.get('ts', 0)
                    if ts:
                        timestamps.append(ts)
            
            if not contents:
                self.analysis_result = self._get_default_analysis()
                return
            
            # åŸºç¡€ç»Ÿè®¡
            total_messages = len(contents)
            avg_length = sum(len(c) for c in contents) / total_messages
            
            # æ—¶é—´æ¨¡å¼åˆ†æ
            time_pattern = await self._analyze_time_pattern(timestamps)
            
            # è¯­è¨€ç‰¹å¾åˆ†æ
            language_features = await self._analyze_language_features(contents)
            
            # æƒ…æ„Ÿåˆ†æ
            emotion_pattern = await self._analyze_emotion_pattern(contents)
            
            # å…³é”®è¯æå–
            keywords = await self._extract_keywords(contents)
            
            self.analysis_result = {
                'total_messages': total_messages,
                'avg_message_length': avg_length,
                'time_pattern': time_pattern,
                'language_features': language_features,
                'emotion_pattern': emotion_pattern,
                'keywords': keywords,
            }
            
            logger.info(f"ä¸ªæ€§åˆ†æå®Œæˆ: {total_messages} æ¡æ¶ˆæ¯, å¹³å‡é•¿åº¦: {avg_length:.1f}")
            
        except Exception as e:
            logger.error(f"ä¸ªæ€§åˆ†æå¤±è´¥: {e}")
            self.analysis_result = self._get_default_analysis()
    
    def _get_default_analysis(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤åˆ†æç»“æœ"""
        return {
            'total_messages': 0,
            'avg_message_length': 0,
            'time_pattern': 'unknown',
            'language_features': {
                'has_emoji': False,
                'has_questions': False,
                'has_exclamations': False,
                'has_links': False,
                'style': 'neutral'
            },
            'emotion_pattern': {
                'positive_ratio': 0.5,
                'negative_ratio': 0.5,
                'neutral_ratio': 0.5,
                'dominant_emotion': 'neutral'
            },
            'keywords': [],
        }
    
    async def _analyze_time_pattern(self, timestamps: List[int]) -> str:
        """åˆ†ææ—¶é—´æ¨¡å¼"""
        import datetime
        
        if not timestamps:
            return "unknown"
        
        # è½¬æ¢ä¸ºå°æ—¶
        hours = []
        for ts in timestamps:
            if ts > 0:
                try:
                    hour = datetime.datetime.fromtimestamp(ts).hour
                    hours.append(hour)
                except:
                    continue
        
        if not hours:
            return "unknown"
        
        avg_hour = sum(hours) / len(hours)
        
        if 6 <= avg_hour < 12:
            return "morning_person"
        elif 12 <= avg_hour < 18:
            return "afternoon_person"
        elif 18 <= avg_hour < 23:
            return "evening_person"
        else:
            return "night_person"
    
    async def _analyze_language_features(self, contents: List[str]) -> Dict[str, Any]:
        """åˆ†æè¯­è¨€ç‰¹å¾"""
        if not contents:
            return {'has_emoji': False, 'has_questions': False, 'has_exclamations': False, 'has_links': False, 'style': 'neutral'}
        
        features = {
            'has_emoji': any('ğŸ˜€' in c or 'ğŸ˜Š' in c or 'ğŸ˜‚' in c for c in contents),
            'has_questions': any('ï¼Ÿ' in c or '?' in c for c in contents),
            'has_exclamations': any('ï¼' in c or '!' in c for c in contents),
            'has_links': any('http' in c or 'www.' in c for c in contents),
        }
        
        # åˆ¤æ–­é£æ ¼
        if features['has_emoji']:
            features['style'] = 'expressive'
        elif features['has_questions']:
            features['style'] = 'inquisitive'
        elif features['has_exclamations']:
            features['style'] = 'enthusiastic'
        else:
            features['style'] = 'neutral'
        
        return features
    
    async def _analyze_emotion_pattern(self, contents: List[str]) -> Dict[str, Any]:
        """åˆ†ææƒ…æ„Ÿæ¨¡å¼"""
        if not contents:
            return {'positive_ratio': 0.5, 'negative_ratio': 0.5, 'neutral_ratio': 0.5, 'dominant_emotion': 'neutral'}
        
        positive_words = ['å¥½', 'æ£’', 'ä¸é”™', 'å–œæ¬¢', 'å¼€å¿ƒ', 'å“ˆå“ˆ', 'è°¢è°¢', 'èµ']
        negative_words = ['ä¸å¥½', 'å·®', 'è®¨åŒ', 'çƒ¦', 'ç”Ÿæ°”', 'éš¾è¿‡', 'æŠ±æ­‰']
        
        positive_count = 0
        negative_count = 0
        
        for content in contents:
            if any(word in content for word in positive_words):
                positive_count += 1
            if any(word in content for word in negative_words):
                negative_count += 1
        
        total = len(contents)
        positive_ratio = positive_count / total if total > 0 else 0
        negative_ratio = negative_count / total if total > 0 else 0
        neutral_ratio = 1 - positive_ratio - negative_ratio
        
        if positive_ratio > negative_ratio and positive_ratio > 0.3:
            dominant_emotion = 'positive'
        elif negative_ratio > positive_ratio and negative_ratio > 0.2:
            dominant_emotion = 'negative'
        else:
            dominant_emotion = 'neutral'
        
        return {
            'positive_ratio': positive_ratio,
            'negative_ratio': negative_ratio,
            'neutral_ratio': neutral_ratio,
            'dominant_emotion': dominant_emotion,
        }
    
    async def _extract_keywords(self, contents: List[str]) -> List[str]:
        """æå–å…³é”®è¯"""
        if not contents:
            return []
        
        # ç®€å•çš„å…³é”®è¯æå–ï¼šå‡ºç°é¢‘ç‡è¾ƒé«˜çš„è¯
        word_freq = {}
        for content in contents:
            words = content.split()
            for word in words:
                if len(word) > 1:  # å¿½ç•¥å•å­—è¯
                    word_freq[word] = word_freq.get(word, 0) + 1
        
        # è¿”å›é¢‘ç‡æœ€é«˜çš„10ä¸ªè¯
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        return [word for word, freq in sorted_words[:10]]
    
    async def _setup_personality_from_analysis(self):
        """åŸºäºåˆ†æç»“æœè®¾ç½®ä¸ªæ€§"""
        if not self.analysis_result:
            return
        
        analysis = self.analysis_result
        
        # è®¾ç½® MBTI
        self.personality.mbti = await self._infer_mbti(analysis)
        
        # è®¾ç½® Big Five
        self.personality.bigfive = await self._generate_bigfive(analysis)
        
        # è®¾ç½®å¹½é»˜é£æ ¼
        self.personality.humor_style = analysis['language_features']['style']
        
        # è®¾ç½®çˆ±æƒ…è¯­è¨€
        self.personality.love_language = await self._infer_love_language(analysis)
    
    async def _infer_mbti(self, analysis: Dict[str, Any]) -> str:
        """åŸºäºåˆ†ææ¨æ–­ MBTI ç±»å‹"""
        if not analysis or analysis.get('total_messages', 0) == 0:
            return "ISFJ"
        
        features = analysis.get('language_features', {})
        emotion = analysis.get('emotion_pattern', {})
        
        # å¤–å‘ vs å†…å‘
        e_i = "E" if analysis.get('total_messages', 0) > 50 else "I"
        
        # å®æ„Ÿ vs ç›´è§‰
        s_n = "N" if features.get('has_questions', False) else "S"
        
        # æ€è€ƒ vs æƒ…æ„Ÿ
        t_f = "F" if emotion.get('dominant_emotion') == 'positive' else "T"
        
        # åˆ¤æ–­ vs çŸ¥è§‰
        j_p = "P" if features.get('style') in ['expressive', 'inquisitive'] else "J"
        
        return f"{e_i}{s_n}{t_f}{j_p}"
    
    async def _generate_bigfive(self, analysis: Dict[str, Any]) -> Dict[str, float]:
        """ç”Ÿæˆ Big Five äººæ ¼ç‰¹è´¨"""
        if not analysis or analysis.get('total_messages', 0) == 0:
            return {"O": 0.5, "C": 0.5, "E": 0.5, "A": 0.5, "N": 0.5}
        
        features = analysis.get('language_features', {})
        emotion = analysis.get('emotion_pattern', {})
        avg_length = analysis.get('avg_message_length', 0)
        
        # å¼€æ”¾æ€§ (Openness)
        openness = 0.8 if features.get('has_questions', False) else 0.4
        
        # å°½è´£æ€§ (Conscientiousness)
        conscientiousness = 0.7 if avg_length > 20 else 0.5
        
        # å¤–å‘æ€§ (Extraversion)
        total_messages = analysis.get('total_messages', 0)
        extraversion = 0.8 if total_messages > 50 else 0.3
        
        # å®œäººæ€§ (Agreeableness)
        agreeableness = 0.8 if emotion.get('dominant_emotion') == 'positive' else 0.4
        
        # ç¥ç»è´¨ (Neuroticism)
        neuroticism = 0.7 if emotion.get('dominant_emotion') == 'negative' else 0.3
        
        return {
            "O": openness,
            "C": conscientiousness,
            "E": extraversion,
            "A": agreeableness,
            "N": neuroticism
        }
    
    async def _infer_love_language(self, analysis: Dict[str, Any]) -> str:
        """æ¨æ–­çˆ±æƒ…è¯­è¨€"""
        if not analysis:
            return "words_of_affirmation"
        
        features = analysis.get('language_features', {})
        avg_length = analysis.get('avg_message_length', 0)
        
        if features.get('style') in ['expressive', 'enthusiastic']:
            return "words_of_affirmation"
        elif avg_length > 30:
            return "quality_time"
        elif features.get('has_emoji'):
            return "receiving_gifts"
        elif features.get('has_questions'):
            return "acts_of_service"
        else:
            return "physical_touch"
    
    def get_analysis_summary(self) -> str:
        """è·å–åˆ†ææ‘˜è¦"""
        if not self.analysis_result:
            return "æš‚æ— åˆ†ææ•°æ®"
        
        analysis = self.analysis_result
        return (
            f"æœ‹å‹ {self.wxid} åˆ†ææ‘˜è¦:\n"
            f"  æ€»æ¶ˆæ¯æ•°: {analysis['total_messages']}\n"
            f"  å¹³å‡é•¿åº¦: {analysis['avg_message_length']:.1f}\n"
            f"  æ—¶é—´æ¨¡å¼: {analysis['time_pattern']}\n"
            f"  è¯­è¨€é£æ ¼: {analysis['language_features']['style']}\n"
            f"  ä¸»å¯¼æƒ…æ„Ÿ: {analysis['emotion_pattern']['dominant_emotion']}\n"
            f"  MBTIç±»å‹: {self.personality.mbti}"
        )
